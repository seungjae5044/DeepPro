{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojW8pWR2dJgi"
   },
   "source": [
    "# **üí°0Ô∏è‚É£ [ ÏïÑÎûò ÏΩîÎìúÎ•º Ïã§ÌñâÌïòÏó¨ Ï°∞Î≥Ñ Î≤àÌò∏Î•º ÏûÖÎ†•ÌïòÏãúÏò§.]üí°**\n",
    "\n",
    "*   1Ï°∞: Î∞ïÏú†ÏßÑ, ÍπÄÏÑúÏó∞, ÏµúÏßÑ\n",
    "*   2Ï°∞: ÏÑúÎØºÍ≤Ω, Ïù¥Ïú†ÏßÑ, ÏµúÎ≤îÏòÅ\n",
    "*   3Ï°∞: Ï†ïÏùÄÏ£º, ÍπÄÏû•Ìôò, Í∂åÏßÑÍ≤Ω\n",
    "*   4Ï°∞: Ï†ïÏßÑÍµê, Ïû•Ï±ÑÏùÄ, Ï°∞ÏÑ±Ìôò\n",
    "*   5Ï°∞: Ï†ÑÏäπÏû¨, Ïã†ÏùÄÌò∏, ÍπÄÏú§Ìù¨\n",
    "*   6Ï°∞: Ï†ïÌòÑÏÑú, ÏßÑÍ≤ΩÏùÄ, Ïù¥Ï†ïÎØº\n",
    "*   7Ï°∞: Ïù¥ÏÑ±ÏßÄ, ÍπÄÎÇ¥Í≤Ω\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_aMFjTcbntUh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ïòà]Ï°∞Ïùò Î≤àÌò∏Î•º ÏûÖÎ†•ÌïòÏãúÏò§: 1\n",
      ">> 6Ï°∞ ÏûÖÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "print(\"[Ïòà]Ï°∞Ïùò Î≤àÌò∏Î•º ÏûÖÎ†•ÌïòÏãúÏò§: 1\")\n",
    "team_idx = int(input(\">> Ï°∞Ïùò Î≤àÌò∏Î•º ÏûÖÎ†•ÌïòÏãúÏò§: \"))\n",
    "print(f\">> {team_idx}Ï°∞ ÏûÖÎãàÎã§.\")\n",
    "team_idx = 'team'+str(team_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ltFiLYoDzdu9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url, extract_archive\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from torchinfo import summary\n",
    "\n",
    "URL = \"https://github.com/JanghunHyeon/AISW4202-Project/releases/download/v.1.1.0/project_dataset.zip\"\n",
    "ROOT = \"./content/data\"\n",
    "ZIP_PATH = os.path.join(ROOT, \"project_dataset.zip\")\n",
    "OUT_DIR  = os.path.join(ROOT, \"project_dataset\")\n",
    "\n",
    "os.makedirs(ROOT, exist_ok=True)\n",
    "download_url(URL, root=ROOT, filename=\"project_dataset.zip\")\n",
    "extract_archive(ZIP_PATH, OUT_DIR)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# ReproduceÎ•º ÏúÑÌïú Seed Í≥†Ï†ï\n",
    "seed_id = 777\n",
    "deterministic = True\n",
    "\n",
    "random.seed(seed_id)\n",
    "np.random.seed(seed_id)\n",
    "torch.manual_seed(seed_id)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(seed_id)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owZuDayDQfCI"
   },
   "source": [
    "# **üí°1Ô∏è‚É£ [ Design your custom model ]üí°**\n",
    "  ## ÏïÑÎûò ÏΩîÎìúÎ•º ÏàòÏ†ïÌïòÏó¨ Î≥∏Ïù∏Ïùò Î™®Îç∏ÏùÑ ÎßåÎì§Ïñ¥ Î≥¥ÏÑ∏Ïöî."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kA09kjRQRJm_"
   },
   "outputs": [],
   "source": [
    "class MyCustomModel(nn.Module):\n",
    "    def __init__(self, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # 48x48\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # 24x24\n",
    "        self.down_sample_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2_1 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.ReLU(),\n",
    "\n",
    "                                     nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=2),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.ReLU(),\n",
    "\n",
    "                                     nn.Conv2d(64, 128, kernel_size=1),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        # 12x12\n",
    "        self.down_sample_layer2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2),\n",
    "                                                nn.BatchNorm2d(256),\n",
    "                                                nn.ReLU())\n",
    "\n",
    "        self.conv3_1 = nn.Sequential(nn.Conv2d(128, 64, kernel_size=1),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.ReLU(),\n",
    "\n",
    "                                     nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=2),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.ReLU(),\n",
    "\n",
    "                                     nn.Conv2d(64, 256, kernel_size=1),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     )\n",
    "        # 6x6\n",
    "        self.conv3_2 = nn.Sequential(nn.Conv2d(256, 128, kernel_size=1),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.ReLU(),\n",
    "\n",
    "                                     nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.ReLU(),\n",
    "\n",
    "                                     nn.Conv2d(128, 256, kernel_size=1),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     )\n",
    "\n",
    "        # 6x6\n",
    "        self.global_pool = nn.AvgPool2d(kernel_size=6)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        identity1 = self.down_sample_layer1(x)\n",
    "        out = self.conv2_1(x)\n",
    "        out = identity1 + out\n",
    "        out = self.relu(out)\n",
    "\n",
    "        identity3 = self.down_sample_layer2(out)\n",
    "        out = self.conv3_1(out)\n",
    "        out = identity3 + out\n",
    "        out = self.relu(out)\n",
    "\n",
    "        identity4 = out\n",
    "        out = self.conv3_2(out)\n",
    "        out = out+identity4\n",
    "        out = self.relu(out)\n",
    "\n",
    "        pool = self.global_pool(out)\n",
    "        fc = pool.view(pool.size(0), -1)\n",
    "        fc = self.fc(fc)\n",
    "\n",
    "        return fc\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HiQdYRtCRLtY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0525,  0.4546,  0.4724,  0.7954,  0.0539,  0.0900, -0.0849, -0.5943,\n",
      "          0.0419,  0.0494,  0.2299, -0.3144,  0.2880, -0.1051, -0.9304]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MyCustomModel(num_classes=15).to(device)\n",
    "\n",
    "inputs = torch.Tensor(1,3,48,48).to(device)\n",
    "out = model(inputs)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iGFrmqopTjku"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyCustomModel                            [1, 15]                   --\n",
       "‚îú‚îÄSequential: 1-1                        [1, 64, 24, 24]           --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-1                       [1, 64, 48, 48]           9,472\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                  [1, 64, 48, 48]           128\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-3                         [1, 64, 48, 48]           --\n",
       "‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                    [1, 64, 24, 24]           --\n",
       "‚îú‚îÄSequential: 1-2                        [1, 128, 12, 12]          --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-5                       [1, 128, 12, 12]          8,320\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                  [1, 128, 12, 12]          256\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-7                         [1, 128, 12, 12]          --\n",
       "‚îú‚îÄSequential: 1-3                        [1, 128, 12, 12]          --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-8                       [1, 64, 24, 24]           4,160\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-9                  [1, 64, 24, 24]           128\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-10                        [1, 64, 24, 24]           --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-11                      [1, 64, 12, 12]           36,928\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-12                 [1, 64, 12, 12]           128\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-13                        [1, 64, 12, 12]           --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-14                      [1, 128, 12, 12]          8,320\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-15                 [1, 128, 12, 12]          256\n",
       "‚îú‚îÄReLU: 1-4                              [1, 128, 12, 12]          --\n",
       "‚îú‚îÄSequential: 1-5                        [1, 256, 6, 6]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-16                      [1, 256, 6, 6]            33,024\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-17                 [1, 256, 6, 6]            512\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-18                        [1, 256, 6, 6]            --\n",
       "‚îú‚îÄSequential: 1-6                        [1, 256, 6, 6]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-19                      [1, 64, 12, 12]           8,256\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-20                 [1, 64, 12, 12]           128\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-21                        [1, 64, 12, 12]           --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-22                      [1, 64, 6, 6]             36,928\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-23                 [1, 64, 6, 6]             128\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-24                        [1, 64, 6, 6]             --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-25                      [1, 256, 6, 6]            16,640\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-26                 [1, 256, 6, 6]            512\n",
       "‚îú‚îÄReLU: 1-7                              [1, 256, 6, 6]            --\n",
       "‚îú‚îÄSequential: 1-8                        [1, 256, 6, 6]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-27                      [1, 128, 6, 6]            32,896\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-28                 [1, 128, 6, 6]            256\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-29                        [1, 128, 6, 6]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-30                      [1, 128, 6, 6]            147,584\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-31                 [1, 128, 6, 6]            256\n",
       "‚îÇ    ‚îî‚îÄReLU: 2-32                        [1, 128, 6, 6]            --\n",
       "‚îÇ    ‚îî‚îÄConv2d: 2-33                      [1, 256, 6, 6]            33,024\n",
       "‚îÇ    ‚îî‚îÄBatchNorm2d: 2-34                 [1, 256, 6, 6]            512\n",
       "‚îú‚îÄReLU: 1-9                              [1, 256, 6, 6]            --\n",
       "‚îú‚îÄAvgPool2d: 1-10                        [1, 256, 1, 1]            --\n",
       "‚îú‚îÄLinear: 1-11                           [1, 15]                   3,855\n",
       "==========================================================================================\n",
       "Total params: 382,607\n",
       "Trainable params: 382,607\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 43.93\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 4.46\n",
       "Params size (MB): 1.53\n",
       "Estimated Total Size (MB): 6.02\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 3, 48, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4870zoF_T52f"
   },
   "source": [
    "# **üí°2Ô∏è‚É£[ Dataset Processing ]üí°**\n",
    "\n",
    "## Dataset for Final Project\n",
    "- Large-scale RGB image dataset\n",
    "  - Training set: about 75,000 images\n",
    "  - Validation set: 900 images\n",
    "  \n",
    "- Dataset specification\n",
    "  - image size: 48 x 48\n",
    "  - RGB scale image (3 channel)\n",
    "  - 15 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "53C2-8_TTqOG"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(OUT_DIR, \"data/ProjectDataset\")\n",
    "trainset = ImageFolder(os.path.join(data_dir, \"train\"), transform=transform_train)\n",
    "valset = ImageFolder(os.path.join(data_dir, \"val\"), transform=transform_val)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=6)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omABX5cXW67v"
   },
   "source": [
    "# **üí°3Ô∏è‚É£[ Train your custom model ]üí°**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gH7IQXB8T_LH"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oMb8Pr7TXBVH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "[1,    50] loss: 2.014\n",
      "[1,   100] loss: 1.704\n",
      "[1,   150] loss: 1.558\n",
      "[1,   200] loss: 1.469\n",
      "[1,   250] loss: 1.408\n",
      "Accuracy of the network on the 1,200 validation images: 54.778 %\n",
      "[2,    50] loss: 1.266\n",
      "[2,   100] loss: 1.229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m optimizer.zero_grad()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     18\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mMyCustomModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     79\u001b[39m out = \u001b[38;5;28mself\u001b[39m.relu(out)\n\u001b[32m     81\u001b[39m identity4 = out\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv3_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m out = out+identity4\n\u001b[32m     84\u001b[39m out = \u001b[38;5;28mself\u001b[39m.relu(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/batchnorm.py:173\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_running_stats:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.momentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[32m    175\u001b[39m             exponential_average_factor = \u001b[32m1.0\u001b[39m / \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_batches_tracked)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 iterations\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    lr_sche.step()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 1,200 validation images: %.3f %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8d0a6czW_CC"
   },
   "source": [
    "# üí°4Ô∏è‚É£ [Model Evaluation]üí°\n",
    "* Validation SetÏùÑ Ïù¥Ïö©Ìïú ÏÑ±Îä• Í≤ÄÏ¶ù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cPTYGtE4XNo3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1,200 validation images: 76.000 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 1,200 validation images: %.3f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48qACLARmBSt"
   },
   "source": [
    "# üí°5Ô∏è‚É£ [Save Model]üí°\n",
    "1. ÏïÑÎûò ÏΩîÎìúÎ•º ÎèôÏûëÌïòÎ©¥ Google Ïù∏Ï¶ù ÌåùÏóÖÏù¥ Îú®Í≥† Ïù∏Ï¶ùÏùÑ ÏöîÏ≤≠.\n",
    "2. Ïù∏Ï¶ùÌõÑ, DriveÏóê Final_Project/ModelÏù¥ÎùºÎäî Ìè¥ÎçîÍ∞Ä ÏÉùÏÑ±Îê®.\n",
    "3. ÏÉùÏÑ±Îêú Ìè¥Îçî ÏïàÏóê **model_{team_idx}.pt** ÎùºÎäî ÌååÏùºÏù¥ ÏÉùÏÑ±Îê®.\n",
    "4. ÏÉùÏÑ±Îêú ÌååÏùºÍ≥º ÏΩîÎìúÎ•º Îã§Ïö¥Î∞õÏïÑ LMSÏóê Ï†úÏ∂ú\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eS87WmNpjgKa"
   },
   "outputs": [],
   "source": [
    "fname = f\"model_{team_idx}.pt\"\n",
    "\n",
    "model.eval()\n",
    "example_input = torch.randn(1,3,48,48).to(device)\n",
    "traced_script = torch.jit.trace(model, example_input)\n",
    "traced_script.save(fname)\n",
    "\n",
    "\n",
    "# Íµ¨Ï∂ïÌïú Îç∞Ïù¥ÌÑ∞ÏÖã Google DriveÎ°ú Ï†ÄÏû•\n",
    "# #from google.colab import drive\n",
    "# import shutil\n",
    "\n",
    "# # 1) Drive ÎßàÏö¥Ìä∏\n",
    "# #drive.mount('/content/drive')\n",
    "# data_dir = './content'\n",
    "# out_dirs = './content/Final_Project/model'\n",
    "# os.makedirs(out_dirs, exist_ok=True)\n",
    "\n",
    "# shutil.copy(os.path.join(data_dir, fname), os.path.join(out_dirs, fname))\n",
    "# print(\"Copied to Drive ‚Üí MyDrive\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
