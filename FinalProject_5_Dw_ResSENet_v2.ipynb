{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojW8pWR2dJgi"
   },
   "source": [
    "# **ğŸ’¡0ï¸âƒ£ [ ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì¡°ë³„ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤.]ğŸ’¡**\n",
    "\n",
    "*   1ì¡°: ë°•ìœ ì§„, ê¹€ì„œì—°, ìµœì§„\n",
    "*   2ì¡°: ì„œë¯¼ê²½, ì´ìœ ì§„, ìµœë²”ì˜\n",
    "*   3ì¡°: ì •ì€ì£¼, ê¹€ì¥í™˜, ê¶Œì§„ê²½\n",
    "*   4ì¡°: ì •ì§„êµ, ì¥ì±„ì€, ì¡°ì„±í™˜\n",
    "*   5ì¡°: ì „ìŠ¹ì¬, ì‹ ì€í˜¸, ê¹€ìœ¤í¬\n",
    "*   6ì¡°: ì •í˜„ì„œ, ì§„ê²½ì€, ì´ì •ë¯¼\n",
    "*   7ì¡°: ì´ì„±ì§€, ê¹€ë‚´ê²½\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_aMFjTcbntUh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì˜ˆ]ì¡°ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤: 1\n",
      ">> 5ì¡° ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(\"[ì˜ˆ]ì¡°ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤: 1\")\n",
    "team_idx = int(input(\">> ì¡°ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤: \"))\n",
    "print(f\">> {team_idx}ì¡° ì…ë‹ˆë‹¤.\")\n",
    "team_idx = 'team'+str(team_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ltFiLYoDzdu9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url, extract_archive\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from torchinfo import summary\n",
    "\n",
    "URL = \"https://github.com/JanghunHyeon/AISW4202-Project/releases/download/v.1.1.0/project_dataset.zip\"\n",
    "ROOT = \"./content/data\"\n",
    "ZIP_PATH = os.path.join(ROOT, \"project_dataset.zip\")\n",
    "OUT_DIR  = os.path.join(ROOT, \"project_dataset\")\n",
    "\n",
    "os.makedirs(ROOT, exist_ok=True)\n",
    "download_url(URL, root=ROOT, filename=\"project_dataset.zip\")\n",
    "extract_archive(ZIP_PATH, OUT_DIR)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Reproduceë¥¼ ìœ„í•œ Seed ê³ ì •\n",
    "seed_id = 777\n",
    "deterministic = True\n",
    "\n",
    "random.seed(seed_id)\n",
    "np.random.seed(seed_id)\n",
    "torch.manual_seed(seed_id)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(seed_id)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owZuDayDQfCI"
   },
   "source": [
    "# **ğŸ’¡1ï¸âƒ£ [ Design your custom model ]ğŸ’¡**\n",
    "  ## ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ë³¸ì¸ì˜ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kA09kjRQRJm_"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# 1. ë¸”ë¡ ì •ì˜\n",
    "############################\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out, stride=1):\n",
    "        super().__init__()\n",
    "        self.depth = nn.Conv2d(c_in, c_in, 3, stride, 1, groups=c_in, bias=False)\n",
    "        self.point = nn.Conv2d(c_in, c_out, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn(self.point(self.depth(x))))\n",
    "        return x\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, ch, r=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(ch, ch // r, bias=False)\n",
    "        self.fc2 = nn.Linear(ch // r, ch, bias=False)\n",
    "        self.act = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x.mean((2,3))                    # Squeeze\n",
    "        s = self.sig(self.fc2(self.act(self.fc1(s))))\n",
    "        s = s.view(s.size(0), -1, 1, 1)\n",
    "        return x * s                         # Excitation\n",
    "\n",
    "class DwResSEBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, stride):\n",
    "        super().__init__()\n",
    "        self.conv = DepthwiseSeparableConv(c_in, c_out, stride)\n",
    "        self.se   = SEBlock(c_out)\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or c_in != c_out:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(c_in, c_out, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(c_out))\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.se(self.conv(x))\n",
    "        out = out + self.skip(x)\n",
    "        return self.act(out)\n",
    "\n",
    "############################\n",
    "# 2. MyCustomModel êµì²´\n",
    "############################\n",
    "class MyCustomModel(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.stage1 = self._make_layer(32,  64,  2, stride=2) # 48â†’24\n",
    "        self.stage2 = self._make_layer(64,  128, 2, stride=2) # 24â†’12\n",
    "        self.stage3 = self._make_layer(128, 256, 3, stride=2) # 12â†’6\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc   = nn.Linear(512, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, c_in, c_out, blocks, stride):\n",
    "        layers = [DwResSEBlock(c_in, c_out, stride)]\n",
    "        layers += [DwResSEBlock(c_out, c_out, 1) for _ in range(blocks-1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HiQdYRtCRLtY"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyCustomModel' object has no attribute 'stage4'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model = MyCustomModel(num_classes=\u001b[32m15\u001b[39m).to(device)\n\u001b[32m      3\u001b[39m inputs = torch.Tensor(\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m48\u001b[39m,\u001b[32m48\u001b[39m).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(out.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mMyCustomModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     75\u001b[39m x = \u001b[38;5;28mself\u001b[39m.stage2(x)\n\u001b[32m     76\u001b[39m x = \u001b[38;5;28mself\u001b[39m.stage3(x)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstage4\u001b[49m(x)\n\u001b[32m     78\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(x).view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MyCustomModel' object has no attribute 'stage4'"
     ]
    }
   ],
   "source": [
    "model = MyCustomModel(num_classes=15).to(device)\n",
    "\n",
    "inputs = torch.Tensor(1,3,48,48).to(device)\n",
    "out = model(inputs)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.8659e-02,  3.0929e-02,  3.9412e-02, -2.2221e-02,  1.1541e-02,\n",
      "         -2.0074e-02, -3.9873e-02,  1.6007e-02,  3.4316e-02, -1.7259e-02,\n",
      "         -1.1037e-02,  2.2265e-02,  2.9167e-02, -7.4874e-05,  1.5028e-02]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iGFrmqopTjku"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MyCustomModel                                 [1, 15]                   --\n",
       "â”œâ”€Sequential: 1-1                             [1, 32, 48, 48]           --\n",
       "â”‚    â””â”€Conv2d: 2-1                            [1, 32, 48, 48]           864\n",
       "â”‚    â””â”€BatchNorm2d: 2-2                       [1, 32, 48, 48]           64\n",
       "â”‚    â””â”€ReLU: 2-3                              [1, 32, 48, 48]           --\n",
       "â”œâ”€Sequential: 1-2                             [1, 64, 24, 24]           --\n",
       "â”‚    â””â”€DwResSEBlock: 2-4                      [1, 64, 24, 24]           --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-1       [1, 64, 24, 24]           2,464\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-2                      [1, 64, 24, 24]           2,048\n",
       "â”‚    â”‚    â””â”€Sequential: 3-3                   [1, 64, 24, 24]           2,176\n",
       "â”‚    â”‚    â””â”€ReLU: 3-4                         [1, 64, 24, 24]           --\n",
       "â”‚    â””â”€DwResSEBlock: 2-5                      [1, 64, 24, 24]           --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-5       [1, 64, 24, 24]           4,800\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-6                      [1, 64, 24, 24]           2,048\n",
       "â”‚    â”‚    â””â”€Sequential: 3-7                   [1, 64, 24, 24]           --\n",
       "â”‚    â”‚    â””â”€ReLU: 3-8                         [1, 64, 24, 24]           --\n",
       "â”œâ”€Sequential: 1-3                             [1, 128, 12, 12]          --\n",
       "â”‚    â””â”€DwResSEBlock: 2-6                      [1, 128, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-9       [1, 128, 12, 12]          9,024\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-10                     [1, 128, 12, 12]          8,192\n",
       "â”‚    â”‚    â””â”€Sequential: 3-11                  [1, 128, 12, 12]          8,448\n",
       "â”‚    â”‚    â””â”€ReLU: 3-12                        [1, 128, 12, 12]          --\n",
       "â”‚    â””â”€DwResSEBlock: 2-7                      [1, 128, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-13      [1, 128, 12, 12]          17,792\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-14                     [1, 128, 12, 12]          8,192\n",
       "â”‚    â”‚    â””â”€Sequential: 3-15                  [1, 128, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€ReLU: 3-16                        [1, 128, 12, 12]          --\n",
       "â”œâ”€Sequential: 1-4                             [1, 256, 6, 6]            --\n",
       "â”‚    â””â”€DwResSEBlock: 2-8                      [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-17      [1, 256, 6, 6]            34,432\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-18                     [1, 256, 6, 6]            32,768\n",
       "â”‚    â”‚    â””â”€Sequential: 3-19                  [1, 256, 6, 6]            33,280\n",
       "â”‚    â”‚    â””â”€ReLU: 3-20                        [1, 256, 6, 6]            --\n",
       "â”‚    â””â”€DwResSEBlock: 2-9                      [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-21      [1, 256, 6, 6]            68,352\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-22                     [1, 256, 6, 6]            32,768\n",
       "â”‚    â”‚    â””â”€Sequential: 3-23                  [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€ReLU: 3-24                        [1, 256, 6, 6]            --\n",
       "â”‚    â””â”€DwResSEBlock: 2-10                     [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-25      [1, 256, 6, 6]            68,352\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-26                     [1, 256, 6, 6]            32,768\n",
       "â”‚    â”‚    â””â”€Sequential: 3-27                  [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€ReLU: 3-28                        [1, 256, 6, 6]            --\n",
       "â”œâ”€Sequential: 1-5                             [1, 512, 3, 3]            --\n",
       "â”‚    â””â”€DwResSEBlock: 2-11                     [1, 512, 3, 3]            --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-29      [1, 512, 3, 3]            134,400\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-30                     [1, 512, 3, 3]            131,072\n",
       "â”‚    â”‚    â””â”€Sequential: 3-31                  [1, 512, 3, 3]            132,096\n",
       "â”‚    â”‚    â””â”€ReLU: 3-32                        [1, 512, 3, 3]            --\n",
       "â”‚    â””â”€DwResSEBlock: 2-12                     [1, 512, 3, 3]            --\n",
       "â”‚    â”‚    â””â”€DepthwiseSeparableConv: 3-33      [1, 512, 3, 3]            267,776\n",
       "â”‚    â”‚    â””â”€SEBlock: 3-34                     [1, 512, 3, 3]            131,072\n",
       "â”‚    â”‚    â””â”€Sequential: 3-35                  [1, 512, 3, 3]            --\n",
       "â”‚    â”‚    â””â”€ReLU: 3-36                        [1, 512, 3, 3]            --\n",
       "â”œâ”€AdaptiveAvgPool2d: 1-6                      [1, 512, 1, 1]            --\n",
       "â”œâ”€Linear: 1-7                                 [1, 15]                   7,695\n",
       "===============================================================================================\n",
       "Total params: 1,172,943\n",
       "Trainable params: 1,172,943\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 24.64\n",
       "===============================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 5.57\n",
       "Params size (MB): 4.69\n",
       "Estimated Total Size (MB): 10.29\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 3, 48, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4870zoF_T52f"
   },
   "source": [
    "# **ğŸ’¡2ï¸âƒ£[ Dataset Processing ]ğŸ’¡**\n",
    "\n",
    "## Dataset for Final Project\n",
    "- Large-scale RGB image dataset\n",
    "  - Training set: about 75,000 images\n",
    "  - Validation set: 900 images\n",
    "  \n",
    "- Dataset specification\n",
    "  - image size: 48 x 48\n",
    "  - RGB scale image (3 channel)\n",
    "  - 15 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "53C2-8_TTqOG"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(OUT_DIR, \"data/ProjectDataset\")\n",
    "trainset = ImageFolder(os.path.join(data_dir, \"train\"), transform=transform_train)\n",
    "valset = ImageFolder(os.path.join(data_dir, \"val\"), transform=transform_val)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=6)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omABX5cXW67v"
   },
   "source": [
    "# **ğŸ’¡3ï¸âƒ£[ Train your custom model ]ğŸ’¡**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gH7IQXB8T_LH"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oMb8Pr7TXBVH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "[1,    50] loss: 2.058\n",
      "[1,   100] loss: 1.671\n",
      "[1,   150] loss: 1.505\n",
      "[1,   200] loss: 1.407\n",
      "[1,   250] loss: 1.317\n",
      "Accuracy of the network on the 1,200 validation images: 6.667 %\n",
      "[2,    50] loss: 1.184\n",
      "[2,   100] loss: 1.150\n",
      "[2,   150] loss: 1.134\n",
      "[2,   200] loss: 1.103\n",
      "[2,   250] loss: 1.065\n",
      "Accuracy of the network on the 1,200 validation images: 6.667 %\n",
      "[3,    50] loss: 0.987\n",
      "[3,   100] loss: 0.970\n",
      "[3,   150] loss: 0.950\n",
      "[3,   200] loss: 0.956\n",
      "[3,   250] loss: 0.930\n",
      "Accuracy of the network on the 1,200 validation images: 6.667 %\n",
      "[4,    50] loss: 0.846\n",
      "[4,   100] loss: 0.860\n",
      "[4,   150] loss: 0.846\n",
      "[4,   200] loss: 0.857\n",
      "[4,   250] loss: 0.859\n",
      "Accuracy of the network on the 1,200 validation images: 6.667 %\n",
      "[5,    50] loss: 0.793\n",
      "[5,   100] loss: 0.798\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m outputs = model(inputs)\n\u001b[32m     17\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m optimizer.step()\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 iterations\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    lr_sche.step()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 1,200 validation images: %.3f %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8d0a6czW_CC"
   },
   "source": [
    "# ğŸ’¡4ï¸âƒ£ [Model Evaluation]ğŸ’¡\n",
    "* Validation Setì„ ì´ìš©í•œ ì„±ëŠ¥ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cPTYGtE4XNo3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1,200 validation images: 6.667 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 1,200 validation images: %.3f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48qACLARmBSt"
   },
   "source": [
    "# ğŸ’¡5ï¸âƒ£ [Save Model]ğŸ’¡\n",
    "1. ì•„ë˜ ì½”ë“œë¥¼ ë™ì‘í•˜ë©´ Google ì¸ì¦ íŒì—…ì´ ëœ¨ê³  ì¸ì¦ì„ ìš”ì²­.\n",
    "2. ì¸ì¦í›„, Driveì— Final_Project/Modelì´ë¼ëŠ” í´ë”ê°€ ìƒì„±ë¨.\n",
    "3. ìƒì„±ëœ í´ë” ì•ˆì— **model_{team_idx}.pt** ë¼ëŠ” íŒŒì¼ì´ ìƒì„±ë¨.\n",
    "4. ìƒì„±ëœ íŒŒì¼ê³¼ ì½”ë“œë¥¼ ë‹¤ìš´ë°›ì•„ LMSì— ì œì¶œ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eS87WmNpjgKa"
   },
   "outputs": [],
   "source": [
    "fname = f\"model_{team_idx}.pt\"\n",
    "\n",
    "model.eval()\n",
    "example_input = torch.randn(1,3,48,48).to(device)\n",
    "traced_script = torch.jit.trace(model, example_input)\n",
    "traced_script.save(fname)\n",
    "\n",
    "\n",
    "# êµ¬ì¶•í•œ ë°ì´í„°ì…‹ Google Driveë¡œ ì €ì¥\n",
    "# #from google.colab import drive\n",
    "# import shutil\n",
    "\n",
    "# # 1) Drive ë§ˆìš´íŠ¸\n",
    "# #drive.mount('/content/drive')\n",
    "# data_dir = './content'\n",
    "# out_dirs = './content/Final_Project/model'\n",
    "# os.makedirs(out_dirs, exist_ok=True)\n",
    "\n",
    "# shutil.copy(os.path.join(data_dir, fname), os.path.join(out_dirs, fname))\n",
    "# print(\"Copied to Drive â†’ MyDrive\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
