{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojW8pWR2dJgi"
   },
   "source": [
    "# **ğŸ’¡0ï¸âƒ£ [ ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì¡°ë³„ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤.]ğŸ’¡**\n",
    "\n",
    "*   1ì¡°: ë°•ìœ ì§„, ê¹€ì„œì—°, ìµœì§„\n",
    "*   2ì¡°: ì„œë¯¼ê²½, ì´ìœ ì§„, ìµœë²”ì˜\n",
    "*   3ì¡°: ì •ì€ì£¼, ê¹€ì¥í™˜, ê¶Œì§„ê²½\n",
    "*   4ì¡°: ì •ì§„êµ, ì¥ì±„ì€, ì¡°ì„±í™˜\n",
    "*   5ì¡°: ì „ìŠ¹ì¬, ì‹ ì€í˜¸, ê¹€ìœ¤í¬\n",
    "*   6ì¡°: ì •í˜„ì„œ, ì§„ê²½ì€, ì´ì •ë¯¼\n",
    "*   7ì¡°: ì´ì„±ì§€, ê¹€ë‚´ê²½\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_aMFjTcbntUh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì˜ˆ]ì¡°ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤: 1\n",
      ">> 5ì¡° ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(\"[ì˜ˆ]ì¡°ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤: 1\")\n",
    "team_idx = int(input(\">> ì¡°ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œì˜¤: \"))\n",
    "print(f\">> {team_idx}ì¡° ì…ë‹ˆë‹¤.\")\n",
    "team_idx = 'team'+str(team_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ltFiLYoDzdu9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url, extract_archive\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "from torchinfo import summary\n",
    "\n",
    "URL = \"https://github.com/JanghunHyeon/AISW4202-Project/releases/download/v.1.1.0/project_dataset.zip\"\n",
    "ROOT = \"./content/data\"\n",
    "ZIP_PATH = os.path.join(ROOT, \"project_dataset.zip\")\n",
    "OUT_DIR  = os.path.join(ROOT, \"project_dataset\")\n",
    "\n",
    "os.makedirs(ROOT, exist_ok=True)\n",
    "download_url(URL, root=ROOT, filename=\"project_dataset.zip\")\n",
    "extract_archive(ZIP_PATH, OUT_DIR)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# Reproduceë¥¼ ìœ„í•œ Seed ê³ ì •\n",
    "seed_id = 777\n",
    "deterministic = True\n",
    "\n",
    "random.seed(seed_id)\n",
    "np.random.seed(seed_id)\n",
    "torch.manual_seed(seed_id)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(seed_id)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owZuDayDQfCI"
   },
   "source": [
    "# **ğŸ’¡1ï¸âƒ£ [ Design your custom model ]ğŸ’¡**\n",
    "  ## ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ë³¸ì¸ì˜ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kA09kjRQRJm_"
   },
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        # Squeeze\n",
    "        se = self.global_pool(x).view(b, c)\n",
    "        # Excitation\n",
    "        se = self.fc1(se)\n",
    "        se = self.relu(se)\n",
    "        se = self.fc2(se)\n",
    "        se = self.sigmoid(se).view(b, c, 1, 1)\n",
    "        # Scale\n",
    "        return x * se.expand_as(x)\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    \"\"\"Depthwise Separable Convolution from Xception\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                 stride=stride, padding=padding, groups=in_channels)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class XceptionBlock(nn.Module):\n",
    "    \"\"\"Modified Xception Block with Residual Connection and SE\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, use_se=True):\n",
    "        super(XceptionBlock, self).__init__()\n",
    "        \n",
    "        self.use_residual = (in_channels == out_channels and stride == 1)\n",
    "        \n",
    "        # Main path with separable convolutions\n",
    "        self.sep_conv1 = SeparableConv2d(in_channels, out_channels, stride=1)\n",
    "        self.sep_conv2 = SeparableConv2d(out_channels, out_channels, stride=stride)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # SE block\n",
    "        self.use_se = use_se\n",
    "        if use_se:\n",
    "            self.se = SEBlock(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        if not self.use_residual:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        # Main path\n",
    "        out = self.sep_conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.sep_conv2(out)\n",
    "        \n",
    "        # SE attention\n",
    "        if self.use_se:\n",
    "            out = self.se(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        if self.use_residual:\n",
    "            out = out + residual\n",
    "        else:\n",
    "            out = out + self.shortcut(residual)\n",
    "        \n",
    "        return self.relu(out)\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        # Squeeze\n",
    "        se = self.global_pool(x).view(b, c)\n",
    "        # Excitation\n",
    "        se = self.fc1(se)\n",
    "        se = self.relu(se)\n",
    "        se = self.fc2(se)\n",
    "        se = self.sigmoid(se).view(b, c, 1, 1)\n",
    "        # Scale\n",
    "        return x * se.expand_as(x)\n",
    "\n",
    "\n",
    "class AdvancedSeparableConv2d(nn.Module):\n",
    "    \"\"\"Advanced Depthwise Separable Convolution with multiple kernel sizes\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1,\n",
    "                 use_multiple_kernels=True, expansion_factor=1):\n",
    "        super(AdvancedSeparableConv2d, self).__init__()\n",
    "        \n",
    "        self.use_multiple_kernels = use_multiple_kernels\n",
    "        expanded_channels = in_channels * expansion_factor\n",
    "        \n",
    "        if use_multiple_kernels:\n",
    "            # Multi-scale depthwise convolution (like MobileNetV2 inspiration)\n",
    "            self.depthwise_3x3 = nn.Conv2d(in_channels, expanded_channels//2, kernel_size=3, \n",
    "                                         stride=stride, padding=1, groups=in_channels)\n",
    "            self.depthwise_5x5 = nn.Conv2d(in_channels, expanded_channels//2, kernel_size=5, \n",
    "                                         stride=stride, padding=2, groups=in_channels)\n",
    "            self.bn_dw = nn.BatchNorm2d(expanded_channels)\n",
    "        else:\n",
    "            # Standard depthwise convolution\n",
    "            self.depthwise = nn.Conv2d(in_channels, expanded_channels, kernel_size=kernel_size, \n",
    "                                     stride=stride, padding=padding, groups=in_channels)\n",
    "            self.bn_dw = nn.BatchNorm2d(expanded_channels)\n",
    "        \n",
    "        # Pointwise convolution\n",
    "        self.pointwise = nn.Conv2d(expanded_channels, out_channels, kernel_size=1)\n",
    "        self.bn_pw = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.use_multiple_kernels:\n",
    "            # Multi-scale feature extraction\n",
    "            dw_3x3 = self.depthwise_3x3(x)\n",
    "            dw_5x5 = self.depthwise_5x5(x)\n",
    "            x = torch.cat([dw_3x3, dw_5x5], dim=1)\n",
    "        else:\n",
    "            x = self.depthwise(x)\n",
    "        \n",
    "        x = self.bn_dw(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn_pw(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MobileNetV2Block(nn.Module):\n",
    "    \"\"\"MobileNetV2 Inverted Residual Block with Depthwise Separable Conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion_factor=6):\n",
    "        super(MobileNetV2Block, self).__init__()\n",
    "        \n",
    "        self.use_residual = (stride == 1 and in_channels == out_channels)\n",
    "        expanded_channels = in_channels * expansion_factor\n",
    "        \n",
    "        # Expansion phase (1x1 conv)\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, expanded_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(expanded_channels),\n",
    "            nn.ReLU()\n",
    "        ) if expansion_factor != 1 else nn.Identity()\n",
    "        \n",
    "        # Depthwise phase (3x3 depthwise conv)\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(expanded_channels, expanded_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, groups=expanded_channels),\n",
    "            nn.BatchNorm2d(expanded_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Pointwise phase (1x1 conv, no activation)\n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(expanded_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        \n",
    "        # SE attention\n",
    "        self.se = SEBlock(out_channels, reduction=8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        # Expansion\n",
    "        x = self.expand(x)\n",
    "        \n",
    "        # Depthwise\n",
    "        x = self.depthwise(x)\n",
    "        \n",
    "        # Pointwise\n",
    "        x = self.pointwise(x)\n",
    "        \n",
    "        # SE attention\n",
    "        x = self.se(x)\n",
    "        \n",
    "        # Residual connection\n",
    "        if self.use_residual:\n",
    "            x = x + residual\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepSeparableBlock(nn.Module):\n",
    "    \"\"\"Deep Separable Block with multiple separable convolutions\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_layers=3, stride=1):\n",
    "        super(DeepSeparableBlock, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        current_channels = in_channels\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            # First layer handles stride, others use stride=1\n",
    "            layer_stride = stride if i == 0 else 1\n",
    "            layer_out_channels = out_channels if i == num_layers - 1 else current_channels\n",
    "            \n",
    "            layers.append(AdvancedSeparableConv2d(\n",
    "                current_channels, layer_out_channels, \n",
    "                stride=layer_stride, use_multiple_kernels=(i % 2 == 0),\n",
    "                expansion_factor=2 if i == 0 else 1\n",
    "            ))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_channels = layer_out_channels\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        # Skip connection\n",
    "        self.use_skip = (in_channels == out_channels and stride == 1)\n",
    "        if not self.use_skip and stride != 1:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        elif not self.use_skip:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.layers(x)\n",
    "        \n",
    "        if self.use_skip:\n",
    "            out = out + residual\n",
    "        else:\n",
    "            out = out + self.skip(residual)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class XceptionBlock(nn.Module):\n",
    "    \"\"\"Enhanced Xception Block with Advanced Separable Convolutions\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1, use_se=True):\n",
    "        super(XceptionBlock, self).__init__()\n",
    "        \n",
    "        self.use_residual = (in_channels == out_channels and stride == 1)\n",
    "        \n",
    "        # Enhanced separable convolutions\n",
    "        self.sep_conv1 = AdvancedSeparableConv2d(in_channels, out_channels, \n",
    "                                               use_multiple_kernels=True, \n",
    "                                               expansion_factor=2)\n",
    "        self.sep_conv2 = AdvancedSeparableConv2d(out_channels, out_channels, \n",
    "                                               stride=stride,\n",
    "                                               use_multiple_kernels=False,\n",
    "                                               expansion_factor=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # SE block\n",
    "        self.use_se = use_se\n",
    "        if use_se:\n",
    "            self.se = SEBlock(out_channels, reduction=8)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        if not self.use_residual:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        # Enhanced separable convolutions\n",
    "        out = self.sep_conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.sep_conv2(out)\n",
    "        \n",
    "        # SE attention\n",
    "        if self.use_se:\n",
    "            out = self.se(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        if self.use_residual:\n",
    "            out = out + residual\n",
    "        else:\n",
    "            out = out + self.shortcut(residual)\n",
    "        \n",
    "        return self.relu(out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        # Main path\n",
    "        out = self.sep_conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.sep_conv2(out)\n",
    "        \n",
    "        # SE attention\n",
    "        if self.use_se:\n",
    "            out = self.se(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        if self.use_residual:\n",
    "            out = out + residual\n",
    "        else:\n",
    "            out = out + self.shortcut(residual)\n",
    "        \n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class MyCustomModel(nn.Module):\n",
    "    def __init__(self, num_classes=15, init_weights=True):\n",
    "        super(MyCustomModel, self).__init__()\n",
    "        \n",
    "        # Entry flow - Initial convolution (48x48 -> 24x24)\n",
    "        self.entry_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Middle flow - Xception blocks with SE attention (24x24 -> 12x12 -> 6x6)\n",
    "        self.xception_block1 = XceptionBlock(64, 128, stride=2, use_se=True)\n",
    "        self.xception_block2 = XceptionBlock(128, 256, stride=2, use_se=True)\n",
    "        self.xception_block3 = XceptionBlock(256, 512, stride=1, use_se=True)\n",
    "        \n",
    "        # Additional residual blocks for better feature extraction\n",
    "        self.res_block1 = self._make_residual_block(512, 512)\n",
    "        \n",
    "        # Exit flow - Final feature extraction\n",
    "        self.exit_conv = nn.Sequential(\n",
    "            SeparableConv2d(512, 728, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(728, 1024, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # SE block for final features\n",
    "        self.final_se = SEBlock(1024, reduction=32)\n",
    "        \n",
    "        # Global average pooling and classifier\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _make_residual_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels // 4, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels // 4, out_channels // 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels // 4, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Entry flow\n",
    "        x = self.entry_conv(x)  # 48x48 -> 24x24, channels: 3 -> 64\n",
    "        \n",
    "        # Middle flow with Xception blocks\n",
    "        x = self.xception_block1(x)  # 24x24 -> 12x12, channels: 64 -> 128\n",
    "        x = self.xception_block2(x)  # 12x12 -> 6x6, channels: 128 -> 256\n",
    "        x = self.xception_block3(x)  # 6x6 -> 6x6, channels: 256 -> 512\n",
    "        \n",
    "        # Additional residual blocks with skip connections\n",
    "        residual1 = x\n",
    "        x = self.res_block1(x)\n",
    "        x = x + residual1\n",
    "        x = nn.ReLU()(x)\n",
    "        \n",
    "        # Exit flow\n",
    "        x = self.exit_conv(x)  # channels: 512 -> 1024\n",
    "        \n",
    "        # Final SE attention\n",
    "        x = self.final_se(x)\n",
    "        \n",
    "        # Global pooling and classification\n",
    "        x = self.global_pool(x)  # 6x6 -> 1x1\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HiQdYRtCRLtY"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyCustomModel' object has no attribute 'xception_block4'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model = MyCustomModel(num_classes=\u001b[32m15\u001b[39m).to(device)\n\u001b[32m      3\u001b[39m inputs = torch.Tensor(\u001b[32m1\u001b[39m,\u001b[32m3\u001b[39m,\u001b[32m48\u001b[39m,\u001b[32m48\u001b[39m).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(out.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 386\u001b[39m, in \u001b[36mMyCustomModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    384\u001b[39m x = \u001b[38;5;28mself\u001b[39m.xception_block2(x)  \u001b[38;5;66;03m# 12x12 -> 6x6, channels: 128 -> 256\u001b[39;00m\n\u001b[32m    385\u001b[39m x = \u001b[38;5;28mself\u001b[39m.xception_block3(x)  \u001b[38;5;66;03m# 6x6 -> 6x6, channels: 256 -> 512\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mxception_block4\u001b[49m(x)  \u001b[38;5;66;03m# 6x6 -> 6x6, channels: 512 -> 512\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# Additional residual blocks with skip connections\u001b[39;00m\n\u001b[32m    389\u001b[39m residual1 = x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/pro/lib/python3.13/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MyCustomModel' object has no attribute 'xception_block4'"
     ]
    }
   ],
   "source": [
    "model = MyCustomModel(num_classes=15).to(device)\n",
    "\n",
    "inputs = torch.Tensor(1,3,48,48).to(device)\n",
    "out = model(inputs)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0931, -0.1128,  0.1240,  0.0888,  0.0082,  0.0536,  0.3186, -0.0539,\n",
      "          0.0479,  0.0663,  0.0693, -0.0390, -0.0170,  0.1689, -0.2925]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iGFrmqopTjku"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyCustomModel                            [1, 15]                   --\n",
       "â”œâ”€Sequential: 1-1                        [1, 64, 24, 24]           --\n",
       "â”‚    â””â”€Conv2d: 2-1                       [1, 32, 24, 24]           896\n",
       "â”‚    â””â”€BatchNorm2d: 2-2                  [1, 32, 24, 24]           64\n",
       "â”‚    â””â”€ReLU: 2-3                         [1, 32, 24, 24]           --\n",
       "â”‚    â””â”€Conv2d: 2-4                       [1, 64, 24, 24]           18,496\n",
       "â”‚    â””â”€BatchNorm2d: 2-5                  [1, 64, 24, 24]           128\n",
       "â”‚    â””â”€ReLU: 2-6                         [1, 64, 24, 24]           --\n",
       "â”œâ”€XceptionBlock: 1-2                     [1, 128, 12, 12]          --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-7      [1, 128, 24, 24]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-1                  [1, 64, 24, 24]           640\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-2                  [1, 64, 24, 24]           1,664\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-3             [1, 128, 24, 24]          256\n",
       "â”‚    â”‚    â””â”€ReLU: 3-4                    [1, 128, 24, 24]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-5                  [1, 128, 24, 24]          16,512\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-6             [1, 128, 24, 24]          256\n",
       "â”‚    â””â”€ReLU: 2-8                         [1, 128, 24, 24]          --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-9      [1, 128, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-7                  [1, 128, 12, 12]          1,280\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-8             [1, 128, 12, 12]          256\n",
       "â”‚    â”‚    â””â”€ReLU: 3-9                    [1, 128, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-10                 [1, 128, 12, 12]          16,512\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-11            [1, 128, 12, 12]          256\n",
       "â”‚    â””â”€SEBlock: 2-10                     [1, 128, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€AdaptiveAvgPool2d: 3-12      [1, 128, 1, 1]            --\n",
       "â”‚    â”‚    â””â”€Linear: 3-13                 [1, 16]                   2,064\n",
       "â”‚    â”‚    â””â”€ReLU: 3-14                   [1, 16]                   --\n",
       "â”‚    â”‚    â””â”€Linear: 3-15                 [1, 128]                  2,176\n",
       "â”‚    â”‚    â””â”€Sigmoid: 3-16                [1, 128]                  --\n",
       "â”‚    â””â”€Sequential: 2-11                  [1, 128, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-17                 [1, 128, 12, 12]          8,320\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-18            [1, 128, 12, 12]          256\n",
       "â”‚    â””â”€ReLU: 2-12                        [1, 128, 12, 12]          --\n",
       "â”œâ”€XceptionBlock: 1-3                     [1, 256, 6, 6]            --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-13     [1, 256, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-19                 [1, 128, 12, 12]          1,280\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-20                 [1, 128, 12, 12]          3,328\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-21            [1, 256, 12, 12]          512\n",
       "â”‚    â”‚    â””â”€ReLU: 3-22                   [1, 256, 12, 12]          --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-23                 [1, 256, 12, 12]          65,792\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-24            [1, 256, 12, 12]          512\n",
       "â”‚    â””â”€ReLU: 2-14                        [1, 256, 12, 12]          --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-15     [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-25                 [1, 256, 6, 6]            2,560\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-26            [1, 256, 6, 6]            512\n",
       "â”‚    â”‚    â””â”€ReLU: 3-27                   [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-28                 [1, 256, 6, 6]            65,792\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-29            [1, 256, 6, 6]            512\n",
       "â”‚    â””â”€SEBlock: 2-16                     [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€AdaptiveAvgPool2d: 3-30      [1, 256, 1, 1]            --\n",
       "â”‚    â”‚    â””â”€Linear: 3-31                 [1, 32]                   8,224\n",
       "â”‚    â”‚    â””â”€ReLU: 3-32                   [1, 32]                   --\n",
       "â”‚    â”‚    â””â”€Linear: 3-33                 [1, 256]                  8,448\n",
       "â”‚    â”‚    â””â”€Sigmoid: 3-34                [1, 256]                  --\n",
       "â”‚    â””â”€Sequential: 2-17                  [1, 256, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-35                 [1, 256, 6, 6]            33,024\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-36            [1, 256, 6, 6]            512\n",
       "â”‚    â””â”€ReLU: 2-18                        [1, 256, 6, 6]            --\n",
       "â”œâ”€XceptionBlock: 1-4                     [1, 512, 6, 6]            --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-19     [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-37                 [1, 256, 6, 6]            2,560\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-38                 [1, 256, 6, 6]            6,656\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-39            [1, 512, 6, 6]            1,024\n",
       "â”‚    â”‚    â””â”€ReLU: 3-40                   [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-41                 [1, 512, 6, 6]            262,656\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-42            [1, 512, 6, 6]            1,024\n",
       "â”‚    â””â”€ReLU: 2-20                        [1, 512, 6, 6]            --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-21     [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-43                 [1, 512, 6, 6]            5,120\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-44            [1, 512, 6, 6]            1,024\n",
       "â”‚    â”‚    â””â”€ReLU: 3-45                   [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-46                 [1, 512, 6, 6]            262,656\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-47            [1, 512, 6, 6]            1,024\n",
       "â”‚    â””â”€SEBlock: 2-22                     [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€AdaptiveAvgPool2d: 3-48      [1, 512, 1, 1]            --\n",
       "â”‚    â”‚    â””â”€Linear: 3-49                 [1, 64]                   32,832\n",
       "â”‚    â”‚    â””â”€ReLU: 3-50                   [1, 64]                   --\n",
       "â”‚    â”‚    â””â”€Linear: 3-51                 [1, 512]                  33,280\n",
       "â”‚    â”‚    â””â”€Sigmoid: 3-52                [1, 512]                  --\n",
       "â”‚    â””â”€Sequential: 2-23                  [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-53                 [1, 512, 6, 6]            131,584\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-54            [1, 512, 6, 6]            1,024\n",
       "â”‚    â””â”€ReLU: 2-24                        [1, 512, 6, 6]            --\n",
       "â”œâ”€XceptionBlock: 1-5                     [1, 512, 6, 6]            --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-25     [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-55                 [1, 512, 6, 6]            5,120\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-56                 [1, 512, 6, 6]            13,312\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-57            [1, 1024, 6, 6]           2,048\n",
       "â”‚    â”‚    â””â”€ReLU: 3-58                   [1, 1024, 6, 6]           --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-59                 [1, 512, 6, 6]            524,800\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-60            [1, 512, 6, 6]            1,024\n",
       "â”‚    â””â”€ReLU: 2-26                        [1, 512, 6, 6]            --\n",
       "â”‚    â””â”€AdvancedSeparableConv2d: 2-27     [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-61                 [1, 512, 6, 6]            5,120\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-62            [1, 512, 6, 6]            1,024\n",
       "â”‚    â”‚    â””â”€ReLU: 3-63                   [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-64                 [1, 512, 6, 6]            262,656\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-65            [1, 512, 6, 6]            1,024\n",
       "â”‚    â””â”€SEBlock: 2-28                     [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€AdaptiveAvgPool2d: 3-66      [1, 512, 1, 1]            --\n",
       "â”‚    â”‚    â””â”€Linear: 3-67                 [1, 64]                   32,832\n",
       "â”‚    â”‚    â””â”€ReLU: 3-68                   [1, 64]                   --\n",
       "â”‚    â”‚    â””â”€Linear: 3-69                 [1, 512]                  33,280\n",
       "â”‚    â”‚    â””â”€Sigmoid: 3-70                [1, 512]                  --\n",
       "â”‚    â””â”€ReLU: 2-29                        [1, 512, 6, 6]            --\n",
       "â”œâ”€Sequential: 1-6                        [1, 512, 6, 6]            --\n",
       "â”‚    â””â”€Conv2d: 2-30                      [1, 128, 6, 6]            65,664\n",
       "â”‚    â””â”€BatchNorm2d: 2-31                 [1, 128, 6, 6]            256\n",
       "â”‚    â””â”€ReLU: 2-32                        [1, 128, 6, 6]            --\n",
       "â”‚    â””â”€Conv2d: 2-33                      [1, 128, 6, 6]            147,584\n",
       "â”‚    â””â”€BatchNorm2d: 2-34                 [1, 128, 6, 6]            256\n",
       "â”‚    â””â”€ReLU: 2-35                        [1, 128, 6, 6]            --\n",
       "â”‚    â””â”€Conv2d: 2-36                      [1, 512, 6, 6]            66,048\n",
       "â”‚    â””â”€BatchNorm2d: 2-37                 [1, 512, 6, 6]            1,024\n",
       "â”œâ”€Sequential: 1-7                        [1, 512, 6, 6]            --\n",
       "â”‚    â””â”€Conv2d: 2-38                      [1, 128, 6, 6]            65,664\n",
       "â”‚    â””â”€BatchNorm2d: 2-39                 [1, 128, 6, 6]            256\n",
       "â”‚    â””â”€ReLU: 2-40                        [1, 128, 6, 6]            --\n",
       "â”‚    â””â”€Conv2d: 2-41                      [1, 128, 6, 6]            147,584\n",
       "â”‚    â””â”€BatchNorm2d: 2-42                 [1, 128, 6, 6]            256\n",
       "â”‚    â””â”€ReLU: 2-43                        [1, 128, 6, 6]            --\n",
       "â”‚    â””â”€Conv2d: 2-44                      [1, 512, 6, 6]            66,048\n",
       "â”‚    â””â”€BatchNorm2d: 2-45                 [1, 512, 6, 6]            1,024\n",
       "â”œâ”€Sequential: 1-8                        [1, 1024, 6, 6]           --\n",
       "â”‚    â””â”€SeparableConv2d: 2-46             [1, 728, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-71                 [1, 512, 6, 6]            5,120\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-72            [1, 512, 6, 6]            1,024\n",
       "â”‚    â”‚    â””â”€ReLU: 3-73                   [1, 512, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-74                 [1, 728, 6, 6]            373,464\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-75            [1, 728, 6, 6]            1,456\n",
       "â”‚    â””â”€ReLU: 2-47                        [1, 728, 6, 6]            --\n",
       "â”‚    â””â”€SeparableConv2d: 2-48             [1, 1024, 6, 6]           --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-76                 [1, 728, 6, 6]            7,280\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-77            [1, 728, 6, 6]            1,456\n",
       "â”‚    â”‚    â””â”€ReLU: 3-78                   [1, 728, 6, 6]            --\n",
       "â”‚    â”‚    â””â”€Conv2d: 3-79                 [1, 1024, 6, 6]           746,496\n",
       "â”‚    â”‚    â””â”€BatchNorm2d: 3-80            [1, 1024, 6, 6]           2,048\n",
       "â”‚    â””â”€ReLU: 2-49                        [1, 1024, 6, 6]           --\n",
       "â”œâ”€SEBlock: 1-9                           [1, 1024, 6, 6]           --\n",
       "â”‚    â””â”€AdaptiveAvgPool2d: 2-50           [1, 1024, 1, 1]           --\n",
       "â”‚    â””â”€Linear: 2-51                      [1, 32]                   32,800\n",
       "â”‚    â””â”€ReLU: 2-52                        [1, 32]                   --\n",
       "â”‚    â””â”€Linear: 2-53                      [1, 1024]                 33,792\n",
       "â”‚    â””â”€Sigmoid: 2-54                     [1, 1024]                 --\n",
       "â”œâ”€AdaptiveAvgPool2d: 1-10                [1, 1024, 1, 1]           --\n",
       "â”œâ”€Dropout: 1-11                          [1, 1024]                 --\n",
       "â”œâ”€Linear: 1-12                           [1, 15]                   15,375\n",
       "==========================================================================================\n",
       "Total params: 3,667,719\n",
       "Trainable params: 3,667,719\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 154.05\n",
       "==========================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 11.33\n",
       "Params size (MB): 14.67\n",
       "Estimated Total Size (MB): 26.03\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 3, 48, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4870zoF_T52f"
   },
   "source": [
    "# **ğŸ’¡2ï¸âƒ£[ Dataset Processing ]ğŸ’¡**\n",
    "\n",
    "## Dataset for Final Project\n",
    "- Large-scale RGB image dataset\n",
    "  - Training set: about 75,000 images\n",
    "  - Validation set: 900 images\n",
    "  \n",
    "- Dataset specification\n",
    "  - image size: 48 x 48\n",
    "  - RGB scale image (3 channel)\n",
    "  - 15 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "53C2-8_TTqOG"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "data_dir = os.path.join(OUT_DIR, \"data/ProjectDataset\")\n",
    "trainset = ImageFolder(os.path.join(data_dir, \"train\"), transform=transform_train)\n",
    "valset = ImageFolder(os.path.join(data_dir, \"val\"), transform=transform_val)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=6)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omABX5cXW67v"
   },
   "source": [
    "# **ğŸ’¡3ï¸âƒ£[ Train your custom model ]ğŸ’¡**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gH7IQXB8T_LH"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oMb8Pr7TXBVH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "[1,    50] loss: 2.078\n",
      "[1,   100] loss: 1.666\n",
      "[1,   150] loss: 1.529\n",
      "[1,   200] loss: 1.400\n",
      "[1,   250] loss: 1.343\n",
      "Accuracy of the network on the 1,200 validation images: 58.556 %\n",
      "[2,    50] loss: 1.189\n",
      "[2,   100] loss: 1.156\n",
      "[2,   150] loss: 1.123\n",
      "[2,   200] loss: 1.097\n",
      "[2,   250] loss: 1.039\n",
      "Accuracy of the network on the 1,200 validation images: 69.333 %\n",
      "[3,    50] loss: 0.977\n",
      "[3,   100] loss: 0.962\n",
      "[3,   150] loss: 0.925\n",
      "[3,   200] loss: 0.936\n",
      "[3,   250] loss: 0.928\n",
      "Accuracy of the network on the 1,200 validation images: 71.889 %\n",
      "[4,    50] loss: 0.828\n",
      "[4,   100] loss: 0.850\n",
      "[4,   150] loss: 0.833\n",
      "[4,   200] loss: 0.836\n",
      "[4,   250] loss: 0.835\n",
      "Accuracy of the network on the 1,200 validation images: 72.556 %\n",
      "[5,    50] loss: 0.764\n",
      "[5,   100] loss: 0.749\n",
      "[5,   150] loss: 0.776\n",
      "[5,   200] loss: 0.765\n",
      "[5,   250] loss: 0.769\n",
      "Accuracy of the network on the 1,200 validation images: 73.556 %\n",
      "[6,    50] loss: 0.686\n",
      "[6,   100] loss: 0.692\n",
      "[6,   150] loss: 0.689\n",
      "[6,   200] loss: 0.694\n",
      "[6,   250] loss: 0.708\n",
      "Accuracy of the network on the 1,200 validation images: 77.000 %\n",
      "[7,    50] loss: 0.646\n",
      "[7,   100] loss: 0.635\n",
      "[7,   150] loss: 0.653\n",
      "[7,   200] loss: 0.643\n",
      "[7,   250] loss: 0.666\n",
      "Accuracy of the network on the 1,200 validation images: 76.444 %\n",
      "[8,    50] loss: 0.587\n",
      "[8,   100] loss: 0.602\n",
      "[8,   150] loss: 0.622\n",
      "[8,   200] loss: 0.613\n",
      "[8,   250] loss: 0.620\n",
      "Accuracy of the network on the 1,200 validation images: 77.000 %\n",
      "[9,    50] loss: 0.550\n",
      "[9,   100] loss: 0.549\n",
      "[9,   150] loss: 0.563\n",
      "[9,   200] loss: 0.596\n",
      "[9,   250] loss: 0.594\n",
      "Accuracy of the network on the 1,200 validation images: 75.556 %\n",
      "[10,    50] loss: 0.517\n",
      "[10,   100] loss: 0.520\n",
      "[10,   150] loss: 0.547\n",
      "[10,   200] loss: 0.547\n",
      "[10,   250] loss: 0.540\n",
      "Accuracy of the network on the 1,200 validation images: 76.778 %\n",
      "[11,    50] loss: 0.443\n",
      "[11,   100] loss: 0.481\n",
      "[11,   150] loss: 0.498\n",
      "[11,   200] loss: 0.488\n",
      "[11,   250] loss: 0.492\n",
      "Accuracy of the network on the 1,200 validation images: 76.667 %\n",
      "[12,    50] loss: 0.417\n",
      "[12,   100] loss: 0.434\n",
      "[12,   150] loss: 0.443\n",
      "[12,   200] loss: 0.455\n",
      "[12,   250] loss: 0.483\n",
      "Accuracy of the network on the 1,200 validation images: 78.667 %\n",
      "[13,    50] loss: 0.390\n",
      "[13,   100] loss: 0.424\n",
      "[13,   150] loss: 0.413\n",
      "[13,   200] loss: 0.450\n",
      "[13,   250] loss: 0.426\n",
      "Accuracy of the network on the 1,200 validation images: 80.000 %\n",
      "[14,    50] loss: 0.364\n",
      "[14,   100] loss: 0.381\n",
      "[14,   150] loss: 0.390\n",
      "[14,   200] loss: 0.418\n",
      "[14,   250] loss: 0.414\n",
      "Accuracy of the network on the 1,200 validation images: 79.000 %\n",
      "[15,    50] loss: 0.336\n",
      "[15,   100] loss: 0.347\n",
      "[15,   150] loss: 0.373\n",
      "[15,   200] loss: 0.382\n",
      "[15,   250] loss: 0.402\n",
      "Accuracy of the network on the 1,200 validation images: 78.889 %\n",
      "[16,    50] loss: 0.303\n",
      "[16,   100] loss: 0.313\n",
      "[16,   150] loss: 0.320\n",
      "[16,   200] loss: 0.337\n",
      "[16,   250] loss: 0.335\n",
      "Accuracy of the network on the 1,200 validation images: 77.556 %\n",
      "[17,    50] loss: 0.271\n",
      "[17,   100] loss: 0.270\n",
      "[17,   150] loss: 0.289\n",
      "[17,   200] loss: 0.316\n",
      "[17,   250] loss: 0.313\n",
      "Accuracy of the network on the 1,200 validation images: 78.889 %\n",
      "[18,    50] loss: 0.237\n",
      "[18,   100] loss: 0.254\n",
      "[18,   150] loss: 0.281\n",
      "[18,   200] loss: 0.281\n",
      "[18,   250] loss: 0.292\n",
      "Accuracy of the network on the 1,200 validation images: 80.222 %\n",
      "[19,    50] loss: 0.232\n",
      "[19,   100] loss: 0.240\n",
      "[19,   150] loss: 0.256\n",
      "[19,   200] loss: 0.275\n",
      "[19,   250] loss: 0.285\n",
      "Accuracy of the network on the 1,200 validation images: 79.333 %\n",
      "[20,    50] loss: 0.218\n",
      "[20,   100] loss: 0.224\n",
      "[20,   150] loss: 0.234\n",
      "[20,   200] loss: 0.246\n",
      "[20,   250] loss: 0.260\n",
      "Accuracy of the network on the 1,200 validation images: 77.222 %\n",
      "[21,    50] loss: 0.195\n",
      "[21,   100] loss: 0.186\n",
      "[21,   150] loss: 0.206\n",
      "[21,   200] loss: 0.207\n",
      "[21,   250] loss: 0.221\n",
      "Accuracy of the network on the 1,200 validation images: 80.222 %\n",
      "[22,    50] loss: 0.159\n",
      "[22,   100] loss: 0.175\n",
      "[22,   150] loss: 0.197\n",
      "[22,   200] loss: 0.193\n",
      "[22,   250] loss: 0.189\n",
      "Accuracy of the network on the 1,200 validation images: 78.000 %\n",
      "[23,    50] loss: 0.141\n",
      "[23,   100] loss: 0.161\n",
      "[23,   150] loss: 0.163\n",
      "[23,   200] loss: 0.182\n",
      "[23,   250] loss: 0.181\n",
      "Accuracy of the network on the 1,200 validation images: 77.667 %\n",
      "[24,    50] loss: 0.139\n",
      "[24,   100] loss: 0.156\n",
      "[24,   150] loss: 0.163\n",
      "[24,   200] loss: 0.162\n",
      "[24,   250] loss: 0.183\n",
      "Accuracy of the network on the 1,200 validation images: 79.000 %\n",
      "[25,    50] loss: 0.140\n",
      "[25,   100] loss: 0.141\n",
      "[25,   150] loss: 0.156\n",
      "[25,   200] loss: 0.157\n",
      "[25,   250] loss: 0.168\n",
      "Accuracy of the network on the 1,200 validation images: 79.778 %\n",
      "[26,    50] loss: 0.127\n",
      "[26,   100] loss: 0.124\n",
      "[26,   150] loss: 0.127\n",
      "[26,   200] loss: 0.137\n",
      "[26,   250] loss: 0.136\n",
      "Accuracy of the network on the 1,200 validation images: 77.333 %\n",
      "[27,    50] loss: 0.113\n",
      "[27,   100] loss: 0.126\n",
      "[27,   150] loss: 0.116\n",
      "[27,   200] loss: 0.124\n",
      "[27,   250] loss: 0.122\n",
      "Accuracy of the network on the 1,200 validation images: 78.222 %\n",
      "[28,    50] loss: 0.099\n",
      "[28,   100] loss: 0.095\n",
      "[28,   150] loss: 0.109\n",
      "[28,   200] loss: 0.114\n",
      "[28,   250] loss: 0.134\n",
      "Accuracy of the network on the 1,200 validation images: 78.889 %\n",
      "[29,    50] loss: 0.097\n",
      "[29,   100] loss: 0.107\n",
      "[29,   150] loss: 0.116\n",
      "[29,   200] loss: 0.115\n",
      "[29,   250] loss: 0.117\n",
      "Accuracy of the network on the 1,200 validation images: 78.333 %\n",
      "[30,    50] loss: 0.091\n",
      "[30,   100] loss: 0.090\n",
      "[30,   150] loss: 0.099\n",
      "[30,   200] loss: 0.114\n",
      "[30,   250] loss: 0.108\n",
      "Accuracy of the network on the 1,200 validation images: 78.333 %\n",
      "[31,    50] loss: 0.092\n",
      "[31,   100] loss: 0.093\n",
      "[31,   150] loss: 0.090\n",
      "[31,   200] loss: 0.095\n",
      "[31,   250] loss: 0.102\n",
      "Accuracy of the network on the 1,200 validation images: 79.333 %\n",
      "[32,    50] loss: 0.076\n",
      "[32,   100] loss: 0.086\n",
      "[32,   150] loss: 0.077\n",
      "[32,   200] loss: 0.087\n",
      "[32,   250] loss: 0.096\n",
      "Accuracy of the network on the 1,200 validation images: 78.000 %\n",
      "[33,    50] loss: 0.064\n",
      "[33,   100] loss: 0.069\n",
      "[33,   150] loss: 0.069\n",
      "[33,   200] loss: 0.082\n",
      "[33,   250] loss: 0.095\n",
      "Accuracy of the network on the 1,200 validation images: 79.111 %\n",
      "[34,    50] loss: 0.073\n",
      "[34,   100] loss: 0.079\n",
      "[34,   150] loss: 0.086\n",
      "[34,   200] loss: 0.087\n",
      "[34,   250] loss: 0.096\n",
      "Accuracy of the network on the 1,200 validation images: 77.000 %\n",
      "[35,    50] loss: 0.079\n",
      "[35,   100] loss: 0.073\n",
      "[35,   150] loss: 0.081\n",
      "[35,   200] loss: 0.084\n",
      "[35,   250] loss: 0.080\n",
      "Accuracy of the network on the 1,200 validation images: 77.111 %\n",
      "[36,    50] loss: 0.071\n",
      "[36,   100] loss: 0.071\n",
      "[36,   150] loss: 0.063\n",
      "[36,   200] loss: 0.071\n",
      "[36,   250] loss: 0.075\n",
      "Accuracy of the network on the 1,200 validation images: 79.778 %\n",
      "[37,    50] loss: 0.058\n",
      "[37,   100] loss: 0.060\n",
      "[37,   150] loss: 0.060\n",
      "[37,   200] loss: 0.064\n",
      "[37,   250] loss: 0.076\n",
      "Accuracy of the network on the 1,200 validation images: 78.889 %\n",
      "[38,    50] loss: 0.054\n",
      "[38,   100] loss: 0.059\n",
      "[38,   150] loss: 0.065\n",
      "[38,   200] loss: 0.064\n",
      "[38,   250] loss: 0.065\n",
      "Accuracy of the network on the 1,200 validation images: 79.000 %\n",
      "[39,    50] loss: 0.056\n",
      "[39,   100] loss: 0.060\n",
      "[39,   150] loss: 0.064\n",
      "[39,   200] loss: 0.063\n",
      "[39,   250] loss: 0.069\n",
      "Accuracy of the network on the 1,200 validation images: 78.778 %\n",
      "[40,    50] loss: 0.061\n",
      "[40,   100] loss: 0.068\n",
      "[40,   150] loss: 0.062\n",
      "[40,   200] loss: 0.062\n",
      "[40,   250] loss: 0.068\n",
      "Accuracy of the network on the 1,200 validation images: 77.889 %\n",
      "[41,    50] loss: 0.051\n",
      "[41,   100] loss: 0.049\n",
      "[41,   150] loss: 0.051\n",
      "[41,   200] loss: 0.045\n",
      "[41,   250] loss: 0.052\n",
      "Accuracy of the network on the 1,200 validation images: 77.556 %\n",
      "[42,    50] loss: 0.049\n",
      "[42,   100] loss: 0.054\n",
      "[42,   150] loss: 0.050\n",
      "[42,   200] loss: 0.049\n",
      "[42,   250] loss: 0.060\n",
      "Accuracy of the network on the 1,200 validation images: 78.444 %\n",
      "[43,    50] loss: 0.051\n",
      "[43,   100] loss: 0.048\n",
      "[43,   150] loss: 0.052\n",
      "[43,   200] loss: 0.050\n",
      "[43,   250] loss: 0.056\n",
      "Accuracy of the network on the 1,200 validation images: 77.889 %\n",
      "[44,    50] loss: 0.041\n",
      "[44,   100] loss: 0.049\n",
      "[44,   150] loss: 0.045\n",
      "[44,   200] loss: 0.047\n",
      "[44,   250] loss: 0.045\n",
      "Accuracy of the network on the 1,200 validation images: 77.667 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m optimizer.step()\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m50\u001b[39m == \u001b[32m49\u001b[39m:    \u001b[38;5;66;03m# print every 50 iterations\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%5d\u001b[39;00m\u001b[33m] loss: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[33m'\u001b[39m %(epoch + \u001b[32m1\u001b[39m, i + \u001b[32m1\u001b[39m, running_loss / \u001b[32m50\u001b[39m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 iterations\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    lr_sche.step()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 1,200 validation images: %.3f %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8d0a6czW_CC"
   },
   "source": [
    "# ğŸ’¡4ï¸âƒ£ [Model Evaluation]ğŸ’¡\n",
    "* Validation Setì„ ì´ìš©í•œ ì„±ëŠ¥ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cPTYGtE4XNo3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1,200 validation images: 6.667 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 1,200 validation images: %.3f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48qACLARmBSt"
   },
   "source": [
    "# ğŸ’¡5ï¸âƒ£ [Save Model]ğŸ’¡\n",
    "1. ì•„ë˜ ì½”ë“œë¥¼ ë™ì‘í•˜ë©´ Google ì¸ì¦ íŒì—…ì´ ëœ¨ê³  ì¸ì¦ì„ ìš”ì²­.\n",
    "2. ì¸ì¦í›„, Driveì— Final_Project/Modelì´ë¼ëŠ” í´ë”ê°€ ìƒì„±ë¨.\n",
    "3. ìƒì„±ëœ í´ë” ì•ˆì— **model_{team_idx}.pt** ë¼ëŠ” íŒŒì¼ì´ ìƒì„±ë¨.\n",
    "4. ìƒì„±ëœ íŒŒì¼ê³¼ ì½”ë“œë¥¼ ë‹¤ìš´ë°›ì•„ LMSì— ì œì¶œ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eS87WmNpjgKa"
   },
   "outputs": [],
   "source": [
    "fname = f\"model_{team_idx}.pt\"\n",
    "\n",
    "model.eval()\n",
    "example_input = torch.randn(1,3,48,48).to(device)\n",
    "traced_script = torch.jit.trace(model, example_input)\n",
    "traced_script.save(fname)\n",
    "\n",
    "\n",
    "# êµ¬ì¶•í•œ ë°ì´í„°ì…‹ Google Driveë¡œ ì €ì¥\n",
    "# #from google.colab import drive\n",
    "# import shutil\n",
    "\n",
    "# # 1) Drive ë§ˆìš´íŠ¸\n",
    "# #drive.mount('/content/drive')\n",
    "# data_dir = './content'\n",
    "# out_dirs = './content/Final_Project/model'\n",
    "# os.makedirs(out_dirs, exist_ok=True)\n",
    "\n",
    "# shutil.copy(os.path.join(data_dir, fname), os.path.join(out_dirs, fname))\n",
    "# print(\"Copied to Drive â†’ MyDrive\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
